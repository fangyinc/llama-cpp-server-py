[project]
name = "llama-cpp-server-py-mono"
version = "0.1.0"
description = "Add your description here"
authors = [
    { name = "Fangyin Cheng", email = "staneyffer@gmail.com" }
]
dependencies = []
readme = "README.md"
requires-python = ">= 3.8"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.rye]
managed = true
virtual = true
dev-dependencies = [
    "pip",
    "tomli>=2.0.2",
    "tomli-w>=1.1.0",
    "pytest>=7.0.0",
    "black>=23.0.0",
    "isort>=5.0.0",
    "twine",
]

[tool.rye.workspace]
members = ["llama-cpp-*"]

[tool.black]
line-length = 88
target-version = ['py38']
include = '\.pyi?$'

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true

[tool.rye.scripts]
fmt = { chain = [
    "black llama-cpp-server-py",
    "black llama-cpp-server-py-core",
    "isort llama-cpp-server-py",
    "isort llama-cpp-server-py-core",
]}
fmt-check = { chain = [
    "black --check llama-cpp-server-py",
    "black --check llama-cpp-server-py-core",
    "isort --check llama-cpp-server-py",
    "isort --check llama-cpp-server-py-core",
]}
# Sync version number across all packages
sync-version = "python scripts/sync_version.py"