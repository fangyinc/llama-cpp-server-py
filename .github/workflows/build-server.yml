# Build llama-cpp-server, Adapted from https://github.com/ggerganov/llama.cpp/blob/master/.github/workflows/build.yml
name: Build server

on:
  workflow_dispatch: # allows manual triggering
    inputs:
      version:
        description: 'Version tag to build (e.g., v1.11.3)'
        required: false
        type: string
      create_release:
        description: 'Create release artifacts'
        required: false
        type: boolean
        default: false
  push:
    branches:
      - main
    paths: ['.github/workflows/build-server.yml', 'llama-cpp-server*/**']
  pull_request:
    paths: ['.github/workflows/build-server.yml', 'llama-cpp-server*/**']

env:
  LLAMA_LOG_COLORS: 1
  LLAMA_LOG_PREFIX: 1
  LLAMA_LOG_TIMESTAMPS: 1
  LLAMA_LOG_VERBOSITY: 10

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build-multi-linux:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]
        arch: [amd64, arm64]
        include:
          - arch: amd64
            platform: x86_64
          - arch: arm64
            platform: aarch64

    steps:
      - name: Clone
        uses: actions/checkout@v4
        with:
          submodules: "recursive"
          ref: ${{ github.event.inputs.version || github.ref }}
          fetch-depth: 0
          fetch-tags: true

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
        with:
          platforms: ${{ matrix.arch }}

      - name: Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libcurl4-openssl-dev

      - name: Build
        run: |
          cd llama.cpp
          mkdir build
          cd build
          cmake .. -DLLAMA_FATAL_WARNINGS=ON -DLLAMA_CURL=ON -DGGML_RPC=ON -DBUILD_SHARED_LIBS=OFF
          cmake --build . --config Release -j $(nproc)

      - name: Test
        run: |
          cd llama.cpp/build
          ctest -L 'main|curl' --verbose --timeout 900

      - name: Determine tag name
        id: tag
        shell: bash
        run: |
          BUILD_NUMBER="$(git rev-list --count HEAD)"
          SHORT_HASH="$(git rev-parse --short=7 HEAD)"
          if [[ "${{ env.BRANCH_NAME }}" == "main" ]]; then
            echo "name=b${BUILD_NUMBER}" >> $GITHUB_OUTPUT
          else
            SAFE_NAME=$(echo "${{ env.BRANCH_NAME }}" | tr '/' '-')
            echo "name=${SAFE_NAME}-b${BUILD_NUMBER}-${SHORT_HASH}" >> $GITHUB_OUTPUT
          fi

      - name: Pack artifacts
        if: ${{ ( github.event_name == 'push' && github.ref == 'refs/heads/main' ) || github.event.inputs.create_release == 'true' }}
        run: |
          cp LICENSE ./llama.cpp/build/bin/
          zip -r llama-${{ steps.tag.outputs.name }}-bin-ubuntu-${{ matrix.arch }}.zip ./llama.cpp/build/bin/*

      - name: Upload artifacts
        if: ${{ ( github.event_name == 'push' && github.ref == 'refs/heads/main' ) || github.event.inputs.create_release == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          path: llama-${{ steps.tag.outputs.name }}-bin-ubuntu-${{ matrix.arch }}.zip
          name: llama-bin-ubuntu-${{ matrix.arch }}.zip

  ubuntu-latest-cmake-cuda:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        arch: [amd64, arm64]
        include:
          - arch: amd64
            platform: linux/amd64
          - arch: arm64
            platform: linux/arm64
    container:
      image: nvidia/cuda:12.6.2-devel-ubuntu24.04
      platform: ${{ matrix.platform }}

    steps:
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
        with:
          platforms: ${{ matrix.arch }}
      - name: Install dependencies
        env:
          DEBIAN_FRONTEND: noninteractive
        run: |
          apt-get update
          apt-get install -y cmake build-essential ninja-build libgomp1 git zip
          git config --global --add safe.directory $GITHUB_WORKSPACE

      - name: Clone
        uses: actions/checkout@v4
        with:
          submodules: "recursive"
          ref: ${{ github.event.inputs.version || github.ref }}
          fetch-depth: 0
          fetch-tags: true

      - name: Build with CMake
        run: |
          cd llama.cpp
          cmake -S . -B build -G Ninja -DCMAKE_BUILD_TYPE=Release -DGGML_NATIVE=OFF -DGGML_CUDA=ON -DCMAKE_EXE_LINKER_FLAGS=-Wl,--allow-shlib-undefined -DLLAMA_FATAL_WARNINGS=ON
          cmake --build build -j $(nproc)

      - name: Determine tag name
        id: tag
        shell: bash
        run: |
          BUILD_NUMBER="$(git rev-list --count HEAD)"
          SHORT_HASH="$(git rev-parse --short=7 HEAD)"
          if [[ "${{ env.BRANCH_NAME }}" == "main" ]]; then
            echo "name=b${BUILD_NUMBER}" >> $GITHUB_OUTPUT
          else
            SAFE_NAME=$(echo "${{ env.BRANCH_NAME }}" | tr '/' '-')
            echo "name=${SAFE_NAME}-b${BUILD_NUMBER}-${SHORT_HASH}" >> $GITHUB_OUTPUT
          fi

      - name: Pack artifacts
        if: ${{ ( github.event_name == 'push' && github.ref == 'refs/heads/main' ) || github.event.inputs.create_release == 'true' }}
        run: |
          cp LICENSE ./llama.cpp/build/
          zip -r llama-${{ steps.tag.outputs.name }}-bin-ubuntu-${{ matrix.arch }}-cuda.zip ./llama.cpp/build/*

      - name: Upload artifacts
        if: ${{ ( github.event_name == 'push' && github.ref == 'refs/heads/main' ) || github.event.inputs.create_release == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          path: llama-${{ steps.tag.outputs.name }}-bin-ubuntu-${{ matrix.arch }}-cuda.zip
          name: llama-bin-ubuntu-${{ matrix.arch }}-cuda.zip